{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT2qLUCQvK1cKAWg7HsIZJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nahgalvao/Trabalho_Reologia_UNESP/blob/main/Reologia_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este pacote é um conjunto de funções que primeiro analisa os dados do Anton-Parr\n",
        "rheometer em uma série de arrays numpy e os salva (rheologyDataParserOld).\n",
        "\n",
        "Depois que os dados são salvos em uma série de matrizes numpy, todas as matrizes podem ser calculadas juntas\n",
        "e salvo em uma matriz numpy média usando dataSetPackager.\n",
        "\n",
        "Todos os dados"
      ],
      "metadata": {
        "id": "GDVN82DdDIMR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MycAN_dksglH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "196b2485-c590-4d32-fb03-5355e166a83a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-baa1bd076843>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfittingFunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fittingFunctions'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import fittingFunctions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rheologyDataParserOld( fileName, outputDirectory ):"
      ],
      "metadata": {
        "id": "5TlSBbcXEPkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta função pega os dados do formato antigo do reômetro Anton-Parr e os analisa em uma série de arquivos de texto que tem menos informações, mas também torna os dados mais fáceis de lidar. Para obter um sentimento para o que esta função está fazendo, dê uma olhada no formato antigo e veja como ele está organizado primeiro.\n",
        "    \n",
        "O fileName é o fileName do arquivo de texto que foi gerado pelo programa Anton-Parr que está no formato que é obtido quando se faz arquivo-->exportar-->conteúdo da janela ativa-->arquivo de texto separado por tabulações. O arquivo exportado devem ser todos da mesma fração de embalagem. O diretório de saída é onde cada conjunto de dados é gerado como um numpy arquivo salvo. Cada arquivo numpy possui uma matriz [N,6] onde N é o número de pontos de dados obtidos e os 6 correspondem as 6 quantidades medidas durante um experimento de taxa de cisalhamento constante [ponto #, tempo, viscosidade, taxa de cisalhamento, tensão de cisalhamento, torque]."
      ],
      "metadata": {
        "id": "l0MST1LpD78u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Carregando o arquivo a ser analisado.\n",
        "* Lemos o arquivo inteiro como uma lista de linhas para facilitar a análise.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xoM3p7S2EXqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    with open(fileName, \"rb\") as f1:\n",
        "         lines = f1.readlines()"
      ],
      "metadata": {
        "id": "TXWyVu37DdR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Precisamos percorrer e encontrar todas as linhas que têm \"Data Series Information\\n\" neles porque essas linhas são as que segmentam nossos dados em diferentes experimentos."
      ],
      "metadata": {
        "id": "TFZOSYvnVcH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    linesWithDataSeriesInfo = np.zeros([0])\n",
        "    counter = 0\n",
        "    for line in lines:\n",
        "        if \"Data Series Information\\r\\n\" in line.decode(encoding=\"utf-8\", errors='ignore'):\n",
        "            linesWithDataSeriesInfo= np.append(linesWithDataSeriesInfo , counter)\n",
        "        counter = counter + 1"
      ],
      "metadata": {
        "id": "ieVNueIMVl0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Agora sabemos que o número total de conjuntos de dados que temos é:"
      ],
      "metadata": {
        "id": "Xu3RTtiBVrM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    totalNumOfExperiments = len(linesWithDataSeriesInfo)\n",
        "\n",
        "    for i in range(0,totalNumOfExperiments):"
      ],
      "metadata": {
        "id": "3XFP4gXiVwd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Isso seleciona um dos blocos de dados e agora precisamos analisá-lo em experimentos separados e o nome do experimento. Estes entrarão em um arquivo de texto que está em um diretório com o nome do experimento"
      ],
      "metadata": {
        "id": "iOLJRRpTV1x7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        if i == totalNumOfExperiments-1:\n",
        "            currentDataSet = lines[ int(linesWithDataSeriesInfo[i]) : int(len(lines)) ]\n",
        "        else:\n",
        "            currentDataSet = lines[ int(linesWithDataSeriesInfo[i]) : int(linesWithDataSeriesInfo[i+1]) ]"
      ],
      "metadata": {
        "id": "LJnqKpJ5WCaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Agora precisamos escolher esse conjunto de dados e obter todas as informações que queremos dele.\n",
        "* Primeiro, obteremos o nome do experimento percorrendo todas as linhas do conjunto de dados e encontrar o nome."
      ],
      "metadata": {
        "id": "C5Gh8Xx7WHXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        for j in range(0, len(currentDataSet)):\n",
        "            if \"Name:\" in currentDataSet[j].decode(encoding=\"utf-8\", errors='ignore'):\n",
        "                nameOfCurrentDataSet = currentDataSet[j][8:]\n",
        "\n",
        "        nameOfCurrentDataSet = nameOfCurrentDataSet.decode(encoding=\"utf-8\", errors='ignore').replace(\"\\r\\n\",\"\")"
      ],
      "metadata": {
        "id": "RBXBgc4cWSI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Agora que temos o nome do conjunto de dados podemos criar um novo diretório dentro do diretório de saída com o nome do experimento."
      ],
      "metadata": {
        "id": "ZtMdnVu8WWwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        filePath = (outputDirectory+os.sep+nameOfCurrentDataSet)\n",
        "        os.mkdir(filePath)"
      ],
      "metadata": {
        "id": "-O0kD6iTWfzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Agora queremos percorrer e encontrar todas as linhas em nosso conjunto de dados que possuem:\n",
        "* \"\\t[s]\\t[Pa·s]\\t[1/s]\\t[Pa]\\t[mNm]\\t[]\\n\"\n",
        "  porque esse é o começo de um conjunto de dados."
      ],
      "metadata": {
        "id": "CKXhQnL9WzH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        linesWhereDataStarts = np.zeros([0])\n",
        "        for k in range(0, len(currentDataSet)):\n",
        "            if \"\\t[s]\\t[Pas]\\t[1/s]\\t[Pa]\\t[mNm]\\t[]\\r\\n\" in currentDataSet[k].decode(encoding=\"utf-8\", errors='ignore'):\n",
        "                linesWhereDataStarts = np.append(linesWhereDataStarts, k)\n",
        "\n",
        "\n",
        "        linesWhereDataStarts=[int(i) for i in linesWhereDataStarts]"
      ],
      "metadata": {
        "id": "wPtL5AyFXCgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Agora que sabemos onde os dados começam, podemos começar a selecionar conjuntos de dados individuais"
      ],
      "metadata": {
        "id": "hrr9Rov9XHXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        linesWhereDataEnds = np.zeros([0])\n",
        "        for j in linesWhereDataStarts:\n",
        "            for k in range(j,len(currentDataSet)):\n",
        "                if currentDataSet[k].decode(encoding=\"utf-8\", errors='ignore') == \"\\r\\n\":\n",
        "                    linesWhereDataEnds = np.append(linesWhereDataEnds, k)\n",
        "                    break\n",
        "\n",
        "        linesWhereDataEnds=[int(i) for i in linesWhereDataEnds]\n",
        "\n",
        "        if len(linesWhereDataEnds)!=len(linesWhereDataStarts):\n",
        "            linesWhereDataEnds = np.append(linesWhereDataEnds, len(currentDataSet) )\n",
        "\n",
        "\n",
        "        for j in range(0,len(linesWhereDataEnds)):\n",
        "\n",
        "            filePathFinal = (outputDirectory+os.sep+nameOfCurrentDataSet)\n",
        "            dataSetToSave = currentDataSet[linesWhereDataStarts[j]+1:linesWhereDataEnds[j]]\n",
        "            finalDataSet = np.zeros((len(dataSetToSave),6))\n",
        "\n",
        "            for k in range(0,len(dataSetToSave)):\n",
        "                finalDataSet[k,:]=np.fromstring(dataSetToSave[k].decode(encoding=\"utf-8\", errors='ignore').replace('\\t',' ').replace(',', '').replace('\\n',''),sep=' ')\n",
        "            finalNameForData = r\"dataSet-\" + str(j) + r\".txt\"\n",
        "            filePathFinal = (outputDirectory+os.sep+nameOfCurrentDataSet+os.sep+finalNameForData)\n",
        "            np.save(filePathFinal,finalDataSet)\n",
        "\n",
        "\n",
        "def dataSetPackager(topDir,baseViscosity=False):"
      ],
      "metadata": {
        "id": "Yz8ijk1BXNV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Esta função pega o caminho topDir e encontra todos os arquivos de dados que terminam em .npy, esses arquivos devem ter sido gerados pela função acima \"oldRheologyDataParser\". Essa função pega os dados brutos do reômetro e os empacota em uma matriz que possui linhas organizadas como [pt#, tempo, viscosidade, taxa de cisalhamento, tensão de cisalhamento, torque]. Esta função carrega em cada curva de fluxo individual gerada por \"oldRheologyDataParser\" e calcula a média dos valores x (tensão de cisalhamento) e calcula a média dos valores y (viscosidade) e gera erros para o ponto de dados médio.\n",
        "    \n",
        "*VOCÊ DEVE EXCLUIR SEUS ARQUIVOS .npy PRESHEAR DE SEU DIRETÓRIO topDir OU ENTÃO ESTA FUNÇÃO IRÁ TENTAR FAZER A MÉDIA DAS entradas:\n",
        "* topDir é o diretório no qual todas as curvas de fluxo que você gostaria de calcular juntas. Exclua os pré-shears desses diretórios CERTIFIQUE-SE DE COLOCAR r ANTES DA STRING, POR EXEMPLO topDir = r\"blah\"\n",
        "* saídas:\n",
        "* It"
      ],
      "metadata": {
        "id": "dWrffNJzXT8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Inicialize os contêineres que conterão todos os conjuntos de dados."
      ],
      "metadata": {
        "id": "K82Phr1OX_dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    dataSetHolder = np.array([])"
      ],
      "metadata": {
        "id": "HZM4SxM8X3Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Este loop encontrará todos os arquivos no topDir que terminam com .npy"
      ],
      "metadata": {
        "id": "dbOlz6bcYEZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    for dirpath, dirnames, filenames in os.walk(topDir):\n",
        "        for filename in [f for f in filenames if f.endswith(r\".npy\")]:\n",
        "\n",
        "            if (filename == r\"averagedData.npy\") or (filename == r\"errorsData.npy\"):\n",
        "              break"
      ],
      "metadata": {
        "id": "KDRkuLgkYKkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Este é o conjunto de dados atual organizado como [pt#, tempo, viscosidade, taxa de cisalhamento, tensão de cisalhamento, torque]"
      ],
      "metadata": {
        "id": "UGFuv5gQYPdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "            currentDataSet = np.expand_dims(np.load(os.path.join(dirpath, filename)),axis=2)"
      ],
      "metadata": {
        "id": "2a52KbP9YZDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* O conjunto de dados atual deve ser ordenado da taxa de cisalhamento controlada mais baixa para a taxa de cisalhamento mais alta, então verificamos e invertemos se necessário."
      ],
      "metadata": {
        "id": "kjx2eKEaYdel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "            if currentDataSet[0,4,0] > currentDataSet[-1,4,0]:\n",
        "                currentDataSet = np.flip(currentDataSet,axis=0)\n",
        "            print(dirpath+os.sep+filename)\n",
        "            if dataSetHolder.any():\n",
        "                dataSetHolder = np.append(dataSetHolder , currentDataSet , axis=2 )\n",
        "            else:\n",
        "                dataSetHolder = currentDataSet\n",
        "\n",
        "\n",
        "    if baseViscosity != False:\n",
        "        dataSetHolder[:,2,:] = dataSetHolder[:,2,:]/baseViscosity\n",
        "\n",
        "    averagedData = np.mean(dataSetHolder,axis=2)\n",
        "    standardDeviationData = np.std(dataSetHolder,axis=2)\n",
        "\n",
        "    if baseViscosity == False:\n",
        "        np.save(os.path.join(topDir, r\"averagedData\"), averagedData )\n",
        "    else:\n",
        "        np.save(os.path.join(topDir, r\"averagedDataVR\"), averagedData )\n",
        "\n",
        "\n",
        "    if baseViscosity == False:\n",
        "        np.save(os.path.join(topDir, r\"errorsData\"), standardDeviationData )\n",
        "    else:\n",
        "        np.save(os.path.join(topDir, r\"errorsDataVR\"), standardDeviationData )\n",
        "\n",
        "    return (averagedData,standardDeviationData)\n",
        "\n",
        "\n",
        "def dataSetCollector(topDir,whichDataSets,finalFileName,flipOrNot=False):\n",
        "\n",
        "    dataSetToJoin = []\n",
        "\n",
        "    for i in whichDataSets:\n",
        "\n",
        "\n",
        "        if dataSetToJoin == []:\n",
        "            dataSetToJoin = np.load(os.path.join(topDir, r\"dataSet-\" +str(i)+r\".txt.npy\" ))\n",
        "        else:\n",
        "            dataSetToJoin = np.concatenate((dataSetToJoin,np.load(os.path.join(topDir, r\"dataSet-\" +str(i)+r\".txt.npy\" ))),axis=0)\n",
        "\n",
        "    if flipOrNot ==  True:\n",
        "        dataSetToJoin = np.flip(dataSetToJoin,axis=0)\n",
        "\n",
        "    np.save(os.path.join(topDir,finalFileName),dataSetToJoin)\n",
        "\n",
        "\n",
        "\n",
        "def tauStarDataPackager(topDir,rescaledViscosity=False):\n",
        "\n",
        "    packagedData = []\n",
        "\n",
        "    listOfSubDirs = next(os.walk(topDir))[1]\n",
        "\n",
        "    for packingFraction in listOfSubDirs:\n",
        "\n",
        "        if rescaledViscosity ==False:\n",
        "            loadInAveragedData = np.load(os.path.join(topDir, packingFraction , r\"averagedData.npy\" ))\n",
        "        else:\n",
        "            loadInAveragedData = np.load(os.path.join(topDir, packingFraction , r\"averagedDataVR.npy\" ))\n",
        "\n",
        "        (numRows,_) = np.shape(loadInAveragedData)\n",
        "\n",
        "        if packagedData == []:\n",
        "            packagedData = np.concatenate((float(packingFraction)*np.ones((numRows,1)),np.expand_dims(loadInAveragedData[:,4],axis=1),np.expand_dims(loadInAveragedData[:,3],axis=1)),axis=1)\n",
        "        else:\n",
        "            packagedData = np.concatenate((packagedData,np.concatenate((float(packingFraction)*np.ones((numRows,1)),np.expand_dims(loadInAveragedData[:,4],axis=1),np.expand_dims(loadInAveragedData[:,3],axis=1)),axis=1)),axis=0)\n",
        "    np.save(os.path.join(topDir,\"tauStarPackagedData\"),packagedData)\n",
        "    return packagedData\n",
        "\n",
        "\n",
        "\n",
        "def prepDataPackager(topDir,errorCornstarchMass,errorSolventMass,errorSolventRho):\n",
        "\n",
        "\n",
        "    errorData = []\n",
        "    listOfSubDirs = next(os.walk(topDir))[1]\n",
        "\n",
        "    for packingFraction in listOfSubDirs:\n",
        "\n",
        "        currentData = np.loadtxt(os.path.join(topDir, packingFraction , r\"prepDetails\" ))\n",
        "\n",
        "        currentData = np.append(currentData,float(packingFraction)/100)\n",
        "\n",
        "        currentData = np.transpose(np.expand_dims(currentData,axis=1))\n",
        "\n",
        "        soluteMass = currentData[0,1]\n",
        "        solventMass = currentData[0,1]\n",
        "        solventRho = currentData[0,2]\n",
        "        soluteRho = currentData[0,3]\n",
        "        errorInCurrentPhi = fittingFunctions.errorInPhiDataPoint(soluteMass,solventMass,soluteRho,solventRho,errorCornstarchMass,errorSolventMass,errorSolventRho)\n",
        "        errorInCurrentPhi = np.expand_dims(errorInCurrentPhi,axis=0)\n",
        "        np.save(os.path.join(topDir, packingFraction , r\"errorInPhi\" ),errorInCurrentPhi)\n",
        "\n",
        "        if errorData == []:\n",
        "            errorData = errorInCurrentPhi\n",
        "        else:\n",
        "            errorData = np.concatenate((errorData,errorInCurrentPhi),axis=0)\n",
        "\n",
        "\n",
        "\n",
        "    return errorData\n",
        "\n",
        "\n",
        "def convertNicolesData(topDir):\n",
        "\n",
        "\n",
        "    listOfSubDirs = next(os.walk(topDir))[1]\n",
        "\n",
        "    for packingFraction in listOfSubDirs:\n",
        "\n",
        "\n",
        "\n",
        "        onlyfiles = [f for f in os.listdir(os.path.join(topDir,packingFraction)) if os.path.isfile(os.path.join(os.path.join(topDir,packingFraction), f))]\n",
        "\n",
        "        nicolesData = np.loadtxt(os.path.join(topDir,packingFraction,onlyfiles[0]))\n",
        "\n",
        "        (numRows,_) = np.shape(nicolesData)\n",
        "\n",
        "        averagedData = np.zeros((numRows,6))\n",
        "        errorData = np.zeros((numRows,6))\n",
        "\n",
        "        averagedData[:,2] = nicolesData[:,2]\n",
        "        averagedData[:,3] = nicolesData[:,1]\n",
        "        averagedData[:,4] = nicolesData[:,0]\n",
        "        errorData[:,2] = nicolesData[:,3]\n",
        "\n",
        "\n",
        "        np.save(os.path.join(topDir,packingFraction,\"averagedData\"),averagedData)\n",
        "        np.save(os.path.join(topDir,packingFraction,\"errorsData\"),errorData)"
      ],
      "metadata": {
        "id": "ZYr64gsTYjXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####"
      ],
      "metadata": {
        "id": "AbGAldIaYtPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import curve_fit\n",
        "import numpy as np\n",
        "import os\n",
        "import plottingFunctions\n",
        "\n",
        "def tauStarFit(packingFractionValues,stressValues,shearRateValues,phi0,phiM,alpha,suspendingViscosity):"
      ],
      "metadata": {
        "id": "QXsZlZFfY4M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* X é uma tupla que é X = (packingFractionValues,stressValues)"
      ],
      "metadata": {
        "id": "aa7jSgasY5gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def strainRateFunc(X,tauStar):\n",
        "        packingFraction,shearStress = X\n",
        "\n",
        "        return (1/suspendingViscosity)*shearStress*(1- packingFraction/(phiM+(phi0-phiM)*np.exp(-shearStress/tauStar)))**alpha\n",
        "\n",
        "    (popt, pcov) = curve_fit(strainRateFunc, (packingFractionValues,stressValues), shearRateValues,bounds=(0, [10000]))\n",
        "\n",
        "    return popt,pcov\n",
        "\n",
        "\n",
        "def allParameterFit(packingFractionValues,stressValues,shearRateValues,suspendingViscosity):"
      ],
      "metadata": {
        "id": "ABTYg1QOY-D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* X é uma tupla que é X = (packingFractionValues,stressValues)"
      ],
      "metadata": {
        "id": "NzvfY9OwZCC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def strainRateFunc(X,tauStar,phiM,phi0,alpha):\n",
        "        packingFraction,shearStress = X\n",
        "\n",
        "        return (1/suspendingViscosity)*shearStress*(1- packingFraction/(phiM+(phi0-phiM)*np.exp(-shearStress/tauStar)))**alpha\n",
        "\n",
        "    (popt, pcov) = curve_fit(strainRateFunc, (packingFractionValues,stressValues), shearRateValues,bounds=(0, [100,.8,.8,5]))\n",
        "\n",
        "    return popt,np.sqrt(np.diag(pcov))\n",
        "\n",
        "\n",
        "def tauStarFitStretchExponential(packingFractionValues,stressValues,shearRateValues,phi0,phiM,alpha,suspendingViscosity):"
      ],
      "metadata": {
        "id": "xpd9pS_nZGKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* X é uma tupla que é X = (packingFractionValues,stressValues)"
      ],
      "metadata": {
        "id": "FNCO7zpDZJph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def strainRateFunc(X,tauStar,beta):\n",
        "        packingFraction,shearStress = X\n",
        "\n",
        "        return (1/suspendingViscosity)*shearStress*(1- packingFraction/(phiM+(phi0-phiM)*np.exp((-shearStress/tauStar)**beta)))**alpha\n",
        "\n",
        "    (popt, pcov) = curve_fit(strainRateFunc, (packingFractionValues,stressValues), shearRateValues,bounds=([0,.999], [10000,1]))\n",
        "\n",
        "    return popt,pcov\n",
        "\n",
        "def errorInPhiDataPoint(cornstarchMass,solventMass,cornstarchRho,solventRho,errorCornstarchMass,errorSolventMass,errorSolventRho):\n",
        "\n",
        "\n",
        "    densityDenom = (solventMass/solventRho) + (cornstarchMass/cornstarchRho)\n",
        "\n",
        "    dPhi_dCornstarchMass = 1/(cornstarchRho*densityDenom) - cornstarchMass/(cornstarchRho*densityDenom)**2\n",
        "\n",
        "    dPhi_dSolventMass = -cornstarchMass/(cornstarchRho*solventRho*densityDenom**2)\n",
        "\n",
        "    dPhi_dSolventDensity = cornstarchMass*solventMass/(cornstarchRho*(solventRho*densityDenom)**2)\n",
        "\n",
        "    return np.sqrt((dPhi_dCornstarchMass*errorCornstarchMass)**2 + (dPhi_dSolventMass*errorSolventMass)**2 + (dPhi_dSolventDensity*errorSolventRho)**2)\n",
        "\n",
        "\n",
        "def newtonianPlateauFinder(topDir,minViscosityList,maxViscosityList,rescaleViscosity=False,tauMin=False,tauMax=False):\n",
        "\n",
        "    listOfSubDirs = next(os.walk(topDir))[1]\n",
        "    listOfSubDirs = [float(i) for i in listOfSubDirs]\n",
        "    listOfSubDirs.sort()\n",
        "    listOfSubDirs = [str(i) for i in listOfSubDirs]\n",
        "    listOfSubDirs = listOfSubDirs[::-1]\n",
        "\n",
        "    if (len(minViscosityList)!=len(listOfSubDirs)) or (len(maxViscosityList)!=len(listOfSubDirs)):\n",
        "        return print(\"The length of minViscosityList and the length of maxViscosityList must be the same as the number of packing fractions in topDir.\")\n",
        "\n",
        "    phiVsMaxViscosity = np.array([])\n",
        "    phiVsMinViscosity = np.array([])\n",
        "\n",
        "    counter = 0\n",
        "    for packingFraction in listOfSubDirs:\n",
        "\n",
        "        if rescaleViscosity == False:\n",
        "            loadInAveragedData = np.load(os.path.join(topDir, packingFraction , r\"averagedData.npy\" ))\n",
        "            loadInErrorData = np.load(os.path.join(topDir, packingFraction , r\"errorsData.npy\" ))\n",
        "        else:\n",
        "            loadInAveragedData = np.load(os.path.join(topDir, packingFraction , r\"averagedDataVR.npy\" ))\n",
        "            loadInErrorData = np.load(os.path.join(topDir, packingFraction , r\"errorsDataVR.npy\" ))\n",
        "\n",
        "        sortedViscosities = np.sort(loadInAveragedData[:,2])\n",
        "\n",
        "        if minViscosityList[counter] == -1:\n",
        "            minViscosity = np.nan\n",
        "            errorOnMinViscosity = np.nan\n",
        "        else:\n",
        "            if tauMin == False:\n",
        "                minViscosity = sortedViscosities[minViscosityList[counter]]\n",
        "                indexOfMinViscosity = np.where(loadInAveragedData[:,2]==minViscosity)\n",
        "                errorOnMinViscosity = loadInErrorData[indexOfMinViscosity[0][0],2]\n",
        "                stressOfMinViscosity = loadInAveragedData[indexOfMinViscosity,4]\n",
        "            else:\n",
        "                tauMinOnset = plottingFunctions.find_nearest(loadInAveragedData[:,4],tauMin)\n",
        "                minViscosity = loadInAveragedData[np.where(loadInAveragedData[:,4]==tauMinOnset),2][0]\n",
        "                indexOfMinViscosity = np.where(loadInAveragedData[:,2]==minViscosity)\n",
        "                errorOnMinViscosity = loadInErrorData[indexOfMinViscosity[0][0],2]\n",
        "                indexOfMinViscosity = np.where(loadInAveragedData[:,2]==minViscosity)\n",
        "                stressOfMinViscosity = loadInAveragedData[indexOfMinViscosity,4]\n",
        "\n",
        "\n",
        "        if maxViscosityList[counter] == -1:\n",
        "            maxViscosity = np.nan\n",
        "            errorOnMaxViscosity = np.nan\n",
        "        else:\n",
        "            if tauMax == False:\n",
        "\n",
        "                maxViscosity = sortedViscosities[-(maxViscosityList[counter]+1)]\n",
        "                indexOfMaxViscosity = np.where(loadInAveragedData[:,2]==maxViscosity)\n",
        "                errorOnMaxViscosity = loadInErrorData[indexOfMaxViscosity[0][0],2]\n",
        "                stressOfMaxViscosity = loadInAveragedData[indexOfMaxViscosity,4]\n",
        "\n",
        "            else:\n",
        "                tauMaxOnset = plottingFunctions.find_nearest(loadInAveragedData[:,4],tauMax)\n",
        "                maxViscosity = loadInAveragedData[np.where(loadInAveragedData[:,4]==tauMaxOnset),2][0]\n",
        "                if len(maxViscosity)!=1:\n",
        "                    maxViscosity=maxViscosity[0]\n",
        "                indexOfMaxViscosity = np.where(loadInAveragedData[:,2]==maxViscosity)\n",
        "                errorOnMaxViscosity = loadInErrorData[indexOfMaxViscosity,2]\n",
        "                indexOfMaxViscosity = np.where(loadInAveragedData[:,2]==maxViscosity)\n",
        "                stressOfMaxViscosity = loadInAveragedData[indexOfMaxViscosity,4]\n",
        "\n",
        "\n",
        "        counter = counter +1\n",
        "        if phiVsMinViscosity.size == 0:\n",
        "\n",
        "            phiVsMinViscosity = np.array([float(packingFraction)/100 ,minViscosity,stressOfMinViscosity])\n",
        "            phiVsMaxViscosity = np.array([float(packingFraction)/100 ,maxViscosity,stressOfMaxViscosity])\n",
        "            phiVsMinViscosityErrors = np.array([float(packingFraction)/100 ,errorOnMinViscosity])\n",
        "            phiVsMaxViscosityErrors = np.array([float(packingFraction)/100 ,errorOnMaxViscosity])\n",
        "\n",
        "        else:\n",
        "            if tauMin==False:\n",
        "                phiVsMinViscosity = np.vstack( (phiVsMinViscosity,np.array([float(packingFraction)/100 ,minViscosity,stressOfMinViscosity])))\n",
        "            else:\n",
        "                phiVsMinViscosity = np.vstack( (phiVsMinViscosity,np.array([float(packingFraction)/100 ,minViscosity[0],stressOfMinViscosity[0]])))\n",
        "\n",
        "            phiVsMaxViscosity = np.vstack( (phiVsMaxViscosity,np.array([float(packingFraction)/100 ,maxViscosity,stressOfMaxViscosity])) )\n",
        "            phiVsMinViscosityErrors = np.vstack( (phiVsMinViscosityErrors,np.array([float(packingFraction)/100 ,errorOnMinViscosity])))\n",
        "            phiVsMaxViscosityErrors = np.vstack( (phiVsMaxViscosityErrors,np.array([float(packingFraction)/100 ,errorOnMaxViscosity])))\n",
        "\n",
        "\n",
        "    phiVsMinViscosity = phiVsMinViscosity[phiVsMinViscosity[:,0].argsort()]\n",
        "    phiVsMaxViscosity = phiVsMaxViscosity[phiVsMaxViscosity[:,0].argsort()]\n",
        "    phiVsMaxViscosityErrors = phiVsMaxViscosityErrors[phiVsMaxViscosityErrors[:,0].argsort()]\n",
        "    phiVsMinViscosityErrors = phiVsMinViscosityErrors[phiVsMinViscosityErrors[:,0].argsort()]\n",
        "\n",
        "    phiVsMinViscosity = phiVsMinViscosity[~np.isnan(phiVsMinViscosity).any(axis=1)]\n",
        "    phiVsMaxViscosity = phiVsMaxViscosity[~np.isnan(phiVsMaxViscosity).any(axis=1)]\n",
        "    phiVsMinViscosityErrors = phiVsMinViscosityErrors[~np.isnan(phiVsMinViscosityErrors).any(axis=1)]\n",
        "    phiVsMaxViscosityErrors = phiVsMaxViscosityErrors[~np.isnan(phiVsMaxViscosityErrors).any(axis=1)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return (phiVsMinViscosity,phiVsMaxViscosity,phiVsMinViscosityErrors,phiVsMaxViscosityErrors)\n",
        "\n",
        "\n",
        "def viscosityDivergenceFit(packingFractions,viscosities,viscosityErrors,suspendingViscosity=False,fixAlpha=False):\n",
        "\n",
        "    if (suspendingViscosity!=False) and (fixAlpha!=False):\n",
        "        def divergingViscosityFunc(x,phiJ):\n",
        "            return  suspendingViscosity*( 1 - (x/phiJ) )**( -fixAlpha )\n",
        "\n",
        "        (phiJ, phiJError) =curve_fit(divergingViscosityFunc,packingFractions,viscosities,sigma=viscosityErrors)\n",
        "        return (phiJ, phiJError)\n",
        "\n",
        "    if (suspendingViscosity!=False) and (fixAlpha==False):\n",
        "        def divergingViscosityFunc(x,phiJ,alpha):\n",
        "            return  suspendingViscosity*( 1 - (x/phiJ) )**( -alpha )\n",
        "        (popt, pcov) =curve_fit(divergingViscosityFunc,packingFractions,viscosities,sigma=viscosityErrors)\n",
        "        errors = np.sqrt(np.diag(pcov))\n",
        "        phiJ = popt[0]\n",
        "        alpha = popt[1]\n",
        "        phiJError = errors[0]\n",
        "        alphaError = errors[1]\n",
        "        return (phiJ, alpha,phiJError,alphaError)\n",
        "\n",
        "\n",
        "    if (suspendingViscosity==False) and (fixAlpha==False):\n",
        "        def divergingViscosityFunc(x,phiJ,alpha):\n",
        "            return  ( 1 - (x/phiJ) )**( -alpha )\n",
        "        (popt, pcov) =curve_fit(divergingViscosityFunc,packingFractions,viscosities,sigma=viscosityErrors)\n",
        "        errors = np.sqrt(np.diag(pcov))\n",
        "        phiJ = popt[0]\n",
        "        alpha = popt[1]\n",
        "        phiJError = errors[0]\n",
        "        alphaError = errors[1]\n",
        "        return (phiJ, alpha,phiJError,alphaError)\n",
        "\n",
        "\n",
        "    if (suspendingViscosity==False) and (fixAlpha!=False):\n",
        "        def divergingViscosityFunc(x,phiJ):\n",
        "            return  ( 1 - (x/phiJ) )**( -fixAlpha )\n",
        "\n",
        "        (phiJ, phiJError) =curve_fit(divergingViscosityFunc,packingFractions,viscosities,sigma=viscosityErrors)\n",
        "        return (phiJ, phiJError)"
      ],
      "metadata": {
        "id": "m78W2cn0ZN3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####"
      ],
      "metadata": {
        "id": "rX20_QrQZVFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot\n",
        "import fittingFunctions\n",
        "\n",
        "\n",
        "\n",
        "def shearStressVsViscosityPlotter(topDir,titleOfPlot=\"normal\",rescaledViscosity=False,noErrors=False):"
      ],
      "metadata": {
        "id": "qR8O9DalZW3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Obtenha uma lista de todos os subdiretórios"
      ],
      "metadata": {
        "id": "2YKsA8KBZbqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    listOfSubDirs = next(os.walk(topDir))[1]\n",
        "    listOfSubDirs = [float(i) for i in listOfSubDirs]\n",
        "    listOfSubDirs.sort()\n",
        "    listOfSubDirs = [str(i) for i in listOfSubDirs]\n",
        "    listOfSubDirs = listOfSubDirs[::-1]\n",
        "\n",
        "    f, ax = pyplot.subplots()\n",
        "\n",
        "\n",
        "    for packingFraction in listOfSubDirs:\n",
        "\n",
        "        if rescaledViscosity == False:\n",
        "            loadInAveragedData = np.load(os.path.join(topDir, packingFraction , r\"averagedData.npy\" ))\n",
        "        else:\n",
        "            loadInAveragedData = np.load(os.path.join(topDir, packingFraction , r\"averagedDataVR.npy\" ))\n",
        "\n",
        "\n",
        "        if noErrors == False:\n",
        "            if rescaledViscosity ==False:\n",
        "                loadInErrordata = np.load(os.path.join(topDir, packingFraction , r\"errorsData.npy\" ))\n",
        "            else:\n",
        "                loadInErrordata = np.load(os.path.join(topDir, packingFraction , r\"errorsDataVR.npy\" ))"
      ],
      "metadata": {
        "id": "KgTmLzBAZfZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Primeiro a plotagem em função da tensão de cisalhamento."
      ],
      "metadata": {
        "id": "BTJ14il6Zjac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        if noErrors == False:\n",
        "            ax.errorbar(loadInAveragedData[:,4],loadInAveragedData[:,2],xerr= loadInErrordata[:,4],yerr=loadInErrordata[:,2],label=packingFraction,marker='o',markersize=5)\n",
        "        else:\n",
        "            ax.plot(loadInAveragedData[:,4],loadInAveragedData[:,2],label=packingFraction,marker='o')"
      ],
      "metadata": {
        "id": "FQ6T9CjrZoo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Em seguida, plote a viscosidade em função da taxa de cisalhamento;"
      ],
      "metadata": {
        "id": "8JAX8rHrZsic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    pyplot.yscale('log')\n",
        "    pyplot.xscale('log')\n",
        "    pyplot.xlabel(\"Shear Stress [Pa]\")\n",
        "\n",
        "    if rescaledViscosity==False:\n",
        "        pyplot.ylabel(\"Viscosity [Pa s]\")\n",
        "    else:\n",
        "        pyplot.ylabel(r\"Rescaled Viscosity $\\frac{\\eta}{\\eta_0}$\")\n",
        "\n",
        "    pyplot.title(titleOfPlot)\n",
        "\n",
        "    pyplot.grid(True)\n",
        "    box = ax.get_position()\n",
        "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
        "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "    return f, ax\n",
        "\n",
        "def tauMinTauMaxPlotter(topDir,tauMin,tauMax,titleOfPlot=\"normal\",rescaledViscosity=False,noErrors=False):\n",
        "\n",
        "\n",
        "    listOfSubDirs = next(os.walk(topDir))[1]\n",
        "\n",
        "    minViscosityList = np.zeros(len(listOfSubDirs))\n",
        "    maxViscosityList = np.zeros(len(listOfSubDirs))\n",
        "\n",
        "    (phiVsMinViscosity,phiVsMaxViscosity,phiVsMinViscosityErrors,phiVsMaxViscosityErrors) = fittingFunctions.newtonianPlateauFinder(topDir,minViscosityList,maxViscosityList,rescaledViscosity,tauMin,tauMax)\n",
        "\n",
        "    f, ax = shearStressVsViscosityPlotter(topDir,titleOfPlot,rescaledViscosity,noErrors)\n",
        "\n",
        "    (numSystems,_) = np.shape(phiVsMaxViscosity)\n",
        "\n",
        "    for i in range(0,numSystems):\n",
        "\n",
        "        ax.plot(phiVsMinViscosity[i,:][2],phiVsMinViscosity[i,:][1],'o',markerSize=15,color=\"red\")\n",
        "        ax.plot(phiVsMaxViscosity[i,:][2],phiVsMaxViscosity[i,:][1],'o',markerSize=15,color=\"blue\")\n",
        "\n",
        "    return f,ax\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def shearRateVsViscosityPlotter(topDir,solvent=\"normal\",rescaleViscosity=False):"
      ],
      "metadata": {
        "id": "2bFfWvloZxXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Obtenha uma lista de todos os subdiretórios"
      ],
      "metadata": {
        "id": "8CZXwSoTZ3Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    listOfSubDirs = next(os.walk(topDir))[1]\n",
        "    listOfSubDirs = [float(i) for i in listOfSubDirs]\n",
        "    listOfSubDirs.sort()\n",
        "    listOfSubDirs = [str(i) for i in listOfSubDirs]\n",
        "    listOfSubDirs = listOfSubDirs[::-1]\n",
        "\n",
        "\n",
        "    ax = pyplot.subplot(111)\n",
        "\n",
        "    for packingFraction in listOfSubDirs:\n",
        "\n",
        "        if rescaleViscosity ==False:\n",
        "            loadInAveragedData = np.load(os.path.join(topDir, packingFraction , r\"averagedData.npy\" ))\n",
        "            loadInErrordata = np.load(os.path.join(topDir, packingFraction , r\"errorsData.npy\" ))\n",
        "        else:\n",
        "            loadInAveragedData = np.load(os.path.join(topDir, packingFraction , r\"averagedDataVR.npy\" ))\n",
        "            loadInErrordata = np.load(os.path.join(topDir, packingFraction , r\"errorsDataVR.npy\" ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "_Xl4Bk3hZ676",
        "outputId": "9a8a49d6-1261-45f8-8fa9-650b6c5eebd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-70be2d2fcff0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlistOfSubDirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlistOfSubDirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistOfSubDirs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlistOfSubDirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlistOfSubDirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistOfSubDirs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlistOfSubDirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistOfSubDirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'topDir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Primeiro a plotagem em função da tensão de cisalhamento."
      ],
      "metadata": {
        "id": "CUtGVJ2oaCg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        ax.errorbar(loadInAveragedData[:,3],loadInAveragedData[:,2],xerr= loadInErrordata[:,3],yerr=loadInErrordata[:,2],label=packingFraction,marker='o')"
      ],
      "metadata": {
        "id": "M0f7QvZQZ-RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Em seguida, plote a viscosidade em função da taxa de cisalhamento,"
      ],
      "metadata": {
        "id": "3PjwTW1paIcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    pyplot.yscale('log')\n",
        "    pyplot.xscale('log')\n",
        "    pyplot.xlabel(r\"Shear Rate [$\\frac{1}{s}$]\")\n",
        "\n",
        "    if rescaleViscosity==False:\n",
        "        pyplot.ylabel(\"Viscosity [Pa s]\")\n",
        "    else:\n",
        "        pyplot.ylabel(r\"Rescaled Viscosity $\\frac{\\eta}{\\eta_0}$\")\n",
        "\n",
        "    if solvent == \"GdCl\":\n",
        "        pyplot.title(\"Flow Curves for GdCl Cornstarch Suspensions\")\n",
        "    if solvent ==\"normal\":\n",
        "        pyplot.title(\"Flow Curves for Normal Cornstarch Suspensions\")\n",
        "\n",
        "    pyplot.grid(True)\n",
        "    box = ax.get_position()\n",
        "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
        "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def viscosityDivergencePlot(viscosityValues,packingFractionValues,viscosityErrors,labelsForCurves,fixAlpha=False,titleOfPlot =\"Newtonian Plateau's Divergences\"):\n",
        "\n",
        "\n",
        "    shapeOfVis = np.shape(viscosityValues)\n",
        "\n",
        "    if np.shape(shapeOfVis)[0]==1:\n",
        "        numSystems=1\n",
        "    else:\n",
        "        numSystems = shapeOfVis[0]\n",
        "\n",
        "    ax = pyplot.subplot(111)\n",
        "\n",
        "    if fixAlpha== False:\n",
        "        def divergingViscosityFunc(x,phiJ, alpha):\n",
        "            return ( 1 - (x/phiJ) )**( -alpha )\n",
        "    else:\n",
        "        def divergingViscosityFunc(x,phiJ):\n",
        "            return ( 1 - (x/phiJ) )**(-fixAlpha)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    phiJHolder = np.zeros(numSystems)\n",
        "    phiJErrorHolder = np.zeros(numSystems)\n",
        "\n",
        "    if fixAlpha == False:\n",
        "        alphaHolder = np.zeros(numSystems)\n",
        "        alphaErrorHolder = np.zeros(numSystems)\n",
        "\n",
        "\n",
        "    for i in range(0,numSystems):\n",
        "        print(numSystems)\n",
        "        if numSystems == 1:\n",
        "            currentViscosityErrors = viscosityErrors\n",
        "            currentPhiValues = packingFractionValues\n",
        "            currentViscosityValues = viscosityValues\n",
        "        else:\n",
        "            currentViscosityErrors = viscosityErrors[i,:]\n",
        "            currentPhiValues = packingFractionValues[i,:]\n",
        "            currentViscosityValues = viscosityValues[i,:]\n",
        "\n",
        "\n",
        "        currentViscosityValues = currentViscosityValues[~np.isnan(currentViscosityValues)]\n",
        "        currentViscosityErrors = currentViscosityErrors[~np.isnan(currentViscosityValues)]\n",
        "        currentPhiValues = currentPhiValues[~np.isnan(currentPhiValues)]\n",
        "\n",
        "        if fixAlpha == False:\n",
        "            (phiJHolder[i],alphaHolder[i],phiJErrorHolder[i],alphaErrorHolder[i]) = fittingFunctions.viscosityDivergenceFit(currentPhiValues,currentViscosityValues,currentViscosityErrors,False,False)\n",
        "            ax.plot(np.linspace(0,phiJHolder[i]-.001,1000),divergingViscosityFunc(np.linspace(0,phiJHolder[i]-.001,1000),phiJHolder[i],alphaHolder[i]),label=labelsForCurves[i] +\" Fit\" )\n",
        "\n",
        "            minimumError = divergingViscosityFunc(np.linspace(0,phiJHolder[i]-.001,1000),phiJHolder[i]-phiJErrorHolder[i],alphaHolder[i]+alphaErrorHolder[i])\n",
        "            maximumError = divergingViscosityFunc(np.linspace(0,phiJHolder[i]-.001,1000),phiJHolder[i]+phiJErrorHolder[i],alphaHolder[i]-alphaErrorHolder[i])\n",
        "            #pyplot.plot(np.linspace(0,phiJHolder[i]-.001,1000),minimumError,label=\"minimumError\")\n",
        "            #pyplot.plot(np.linspace(0,phiJHolder[i]-.001,1000), maximumError,label=\"maximumError\")\n",
        "\n",
        "            ax.fill_between(np.linspace(0,phiJHolder[i]-.001,1000), minimumError, maximumError, where=maximumError <= minimumError, facecolor='lightblue')\n",
        "        else:\n",
        "            (phiJHolder[i],phiJErrorHolder[i]) = fittingFunctions.viscosityDivergenceFit(currentPhiValues,currentViscosityValues,currentViscosityErrors,False,fixAlpha)\n",
        "            minimumError = divergingViscosityFunc(np.linspace(0,phiJHolder[i]-.001,1000),phiJHolder[i]-phiJErrorHolder[i])\n",
        "            maximumError = divergingViscosityFunc(np.linspace(0,phiJHolder[i]-.001,1000),phiJHolder[i]+phiJErrorHolder[i])\n",
        "            ax.fill_between(np.linspace(0,phiJHolder[i]-.001,1000), minimumError, maximumError, where=maximumError <= minimumError, facecolor='lightblue')\n",
        "\n",
        "            ax.plot(np.linspace(0,phiJHolder[i]-.001,1000),divergingViscosityFunc(np.linspace(0,phiJHolder[i]-.001,1000),phiJHolder[i]),label=labelsForCurves[i] +\" Fit\" )\n",
        "        print(currentViscosityErrors)\n",
        "        ax.errorbar(currentPhiValues, currentViscosityValues,fmt='o',yerr=currentViscosityErrors,label=labelsForCurves[i])\n",
        "\n",
        "\n",
        "\n",
        "    ax.legend()\n",
        "    box = ax.get_position()\n",
        "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
        "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    pyplot.title(titleOfPlot)\n",
        "    pyplot.xlabel(\"Packing Fraction $\\phi$\")\n",
        "    pyplot.ylabel(\"Rescaled Viscosity $\\eta_R$\")\n",
        "    pyplot.xlim(np.nanmin(packingFractionValues)-.05,np.nanmax(packingFractionValues)+.04)\n",
        "    pyplot.ylim(0,np.nanmax(viscosityValues)+20)\n",
        "    if fixAlpha == False:\n",
        "        return (phiJHolder,alphaHolder,phiJErrorHolder,alphaErrorHolder)\n",
        "    else:\n",
        "        return (phiJHolder,phiJErrorHolder)\n",
        "\n",
        "\n",
        "def logarithmicPlotter(viscosityValues0,viscosityValues1,packingFractionValues0,packingFractionValues1,alpha0,phiJ0,alpha1,phiJ1,highOrLow):\n",
        "\n",
        "    logViscosityValues0 = np.log10(viscosityValues0)\n",
        "    logPackingFraction0 = np.log10(1-packingFractionValues0/phiJ0)\n",
        "\n",
        "    logViscosityValues1 = np.log10(viscosityValues1)\n",
        "    logPackingFraction1 = np.log10(1-packingFractionValues1/phiJ1)\n",
        "\n",
        "\n",
        "    pyplot.plot(logPackingFraction0,logViscosityValues0,'o')\n",
        "\n",
        "    pyplot.plot(logPackingFraction1,logViscosityValues1,'o')\n",
        "    #pyplot.title()\n",
        "    if highOrLow == \"high\":\n",
        "        pyplot.xlabel(r\"$\\log(1-\\frac{\\phi}{\\phi_M})$\")\n",
        "        pyplot.title(\"Frictional Newtonian Regimes\")\n",
        "\n",
        "    if highOrLow == \"low\":\n",
        "        pyplot.xlabel(r\"$\\log(1-\\frac{\\phi}{\\phi_0})$\")\n",
        "        pyplot.title(\"Frictionless Newtonian Regimes\")\n",
        "\n",
        "\n",
        "    pyplot.legend((\"Pure Cornstarch Suspension\",\"GdCl Cornstarch Suspension\"))\n",
        "    pyplot.ylabel(r\"$\\log(\\eta)$\")\n",
        "\n",
        "    font = {'family' : 'normal',\n",
        "\n",
        "        'size'   : 10}\n",
        "\n",
        "    pyplot.rc('font', **font)\n",
        "    #pyplot.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "\n",
        "def logarithmicPlotterAllLines(phiVsMinViscosityG,phiVsMinViscosityC,phiVsMaxViscosityG,phiVsMaxViscosityC,phiMG,alphaMG,phi0G,alpha0G,phiMC,alphaMC,phi0C,alpha0C,suspendViscosityC,suspendViscosityG):\n",
        "\n",
        "\n",
        "    logViscosityValuesC_0= np.log10(phiVsMinViscosityC[:,1])\n",
        "    logPackingFractionC_0 = np.log10(1-phiVsMinViscosityC[:,0]/phi0C)\n",
        "    logViscosityValuesG_0= np.log10(phiVsMinViscosityG[:,1])\n",
        "    logPackingFractionG_0 = np.log10(1-phiVsMinViscosityG[:,0]/phi0G)\n",
        "\n",
        "    logViscosityValuesC_M= np.log10(phiVsMaxViscosityC[:,1])\n",
        "    logPackingFractionC_M = np.log10(1-phiVsMaxViscosityC[:,0]/phiMC)\n",
        "    logViscosityValuesG_M= np.log10(phiVsMaxViscosityG[:,1])\n",
        "    logPackingFractionG_M = np.log10(1-phiVsMaxViscosityG[:,0]/phiMG)\n",
        "\n",
        "\n",
        "\n",
        "    pyplot.plot(logPackingFractionC_0,logViscosityValuesC_0,'o',label=\"Frictionless Cornstarch\")\n",
        "    pyplot.plot(logPackingFractionG_0,logViscosityValuesG_0,'o',label=\"Frictionless Cornstarch/GdCl\")\n",
        "    pyplot.plot(logPackingFractionC_M,logViscosityValuesC_M,'o',label=\"Frictional Cornstarch\")\n",
        "    pyplot.plot(logPackingFractionG_M,logViscosityValuesG_M,'o',label=\"Frictional Cornstarch/GdCl\")\n",
        "\n",
        "\n",
        "    pyplot.legend()\n",
        "    pyplot.xlabel(r\"$\\log(1-\\frac{\\phi}{\\phi_J})$\")\n",
        "    pyplot.ylabel(r\"$\\log(\\eta)$\")\n",
        "\n",
        "\n",
        "\n",
        "def sideBySideCurvePlot(topDir1,topDir2,topDir3,outputDir,rescaledViscosity=False,allPlots=False,evenCurves=\"none\"):\n",
        "\n",
        "    #get list of all of the subdirectories in topDir1 and topDir2\n",
        "    dirsIn1 = next(os.walk(topDir1))[1]\n",
        "    dirsIn2 = next(os.walk(topDir2))[1]\n",
        "    dirsIn3 = next(os.walk(topDir3))[1]\n",
        "    #They need to be sorted so we have to convert them from strings to floats and then back\n",
        "    dirsIn1 = np.sort([float(i) for i in dirsIn1])\n",
        "    dirsIn2 = np.sort([float(i) for i in dirsIn2])\n",
        "    dirsIn3 = np.sort([float(i) for i in dirsIn3])\n",
        "    #Back to strings!\n",
        "    dirsIn1 = [str(i) for i in dirsIn1]\n",
        "    dirsIn2 = [str(i) for i in dirsIn2]\n",
        "    dirsIn3 = [str(i) for i in dirsIn3]\n",
        "\n",
        "    pyplot.figure(figsize=(14.0, 5.0))\n",
        "\n",
        "\n",
        "    markersForPlots = [\"o\",\"x\",\"D\",\"h\",\"+\",\"P\"]\n",
        "\n",
        "    for i in range(0,len(dirsIn1)):\n",
        "\n",
        "        if allPlots == True:\n",
        "            if evenCurves == \"even\":\n",
        "                if i%2!=0:\n",
        "                    continue\n",
        "            if evenCurves == \"odd\":\n",
        "                if i%2==0:\n",
        "                    continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if rescaledViscosity == True:\n",
        "            dir1Data = np.load(os.path.join(topDir1,dirsIn1[i], r\"averagedDataVR.npy\"))\n",
        "            dir1Errors = np.load(os.path.join(topDir1,dirsIn1[i], r\"errorsDataVR.npy\"))\n",
        "            dir2Data = np.load(os.path.join(topDir2,dirsIn2[i], r\"averagedDataVR.npy\"))\n",
        "            dir2Errors = np.load(os.path.join(topDir2,dirsIn2[i], r\"errorsDataVR.npy\"))\n",
        "            dir3Data = np.load(os.path.join(topDir3,dirsIn3[i], r\"averagedDataVR.npy\"))\n",
        "            dir3Errors = np.load(os.path.join(topDir3,dirsIn3[i], r\"errorsDataVR.npy\"))\n",
        "        else:\n",
        "            dir1Data = np.load(os.path.join(topDir1,dirsIn1[i], r\"averagedData.npy\"))\n",
        "            dir1Errors = np.load(os.path.join(topDir1,dirsIn1[i], r\"errorsData.npy\"))\n",
        "            dir2Data = np.load(os.path.join(topDir2,dirsIn2[i], r\"averagedData.npy\"))\n",
        "            dir2Errors = np.load(os.path.join(topDir2,dirsIn2[i], r\"errorsData.npy\"))\n",
        "            dir3Data = np.load(os.path.join(topDir3,dirsIn3[i], r\"averagedData.npy\"))\n",
        "            dir3Errors = np.load(os.path.join(topDir3,dirsIn3[i], r\"errorsData.npy\"))\n",
        "\n",
        "\n",
        "        pyplot.errorbar(dir1Data[:,4],dir1Data[:,2],yerr=dir1Errors[:,2],label=dirsIn1[i]+\"C\",marker=markersForPlots[i],color=\"black\", markersize=10)\n",
        "        pyplot.errorbar(dir2Data[:,4],dir2Data[:,2],yerr=dir2Errors[:,2],label=dirsIn2[i]+\"GdCl\",marker=markersForPlots[i],color=\"red\", markersize=10)\n",
        "        pyplot.errorbar(dir3Data[:,4],dir3Data[:,2],yerr=dir3Errors[:,2],label=dirsIn3[i]+\"NH4\",marker=markersForPlots[i],color=\"blue\", markersize=10)\n",
        "\n",
        "        figName = str(round(float(dirsIn1[i])))\n",
        "        pyplot.yscale('log')\n",
        "        pyplot.xscale('log')\n",
        "        pyplot.xlabel(r\"Shear Stress [Pa]\")\n",
        "\n",
        "\n",
        "        if rescaledViscosity == True:\n",
        "            pyplot.ylabel(r\"Rescaled Viscosity $\\frac{\\eta}{\\eta_0}$\")\n",
        "        else:\n",
        "            pyplot.ylabel(r\"Viscosity $\\eta$ [Pa s]\")\n",
        "\n",
        "        pyplot.legend()\n",
        "\n",
        "\n",
        "        if allPlots == False:\n",
        "            if rescaledViscosity == True:\n",
        "                pyplot.savefig(os.path.join(outputDir,figName+\"rescaled\"))\n",
        "            else:\n",
        "                pyplot.savefig(os.path.join(outputDir,figName))\n",
        "            pyplot.clf()\n",
        "        else:\n",
        "            pyplot.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "\n",
        "    if allPlots == True:\n",
        "        pyplot.savefig(os.path.join(outputDir,\"all\"+evenCurves+\"plots\"))\n",
        "\n",
        "\n",
        "\n",
        "def shearJammingPhaseDiagram(phi0,phiM,tauStar,alpha):"
      ],
      "metadata": {
        "id": "bt90dBoWaNuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Isso gera um gráfico do diagrama de fase de interferência de cisalhamento usando o modelo Wyart-Cates. Este modelo é descrito no papel encontrado aqui:\n",
        "* https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.112.098302\n",
        "    \n",
        "* Este modelo dá a taxa de cisalhamento em função da densidade de sua suspensão e em função da tensão de cisalhamento:\n",
        "* gammaDot = (1/eta_0)*tau*(1+phi/(phiM+(phi0-phiM)*e^(-tau/tauStar)))^alpha\n",
        "* onde gammaDot é a taxa de cisalhamento, eta_0 é a viscosidade do solvente de suspensão tau é a tensão de cisalhamento, phi é a densidade, phi0 é a densidade de interferência sem atrito, phiM é a densidade de interferência por fricção e alpha é um parâmetro livre no modelo .\n",
        "* Estes são os valores y ou as tensões usadas para cada curva"
      ],
      "metadata": {
        "id": "TP2br2LQaYnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    stressValues = np.linspace(10**-5,10**5,100000)"
      ],
      "metadata": {
        "id": "EDcarGmTau3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Encontre a linha DST em função dos valores de estresse definidos acima. Esta função retorna frações de empacotamento em função da tensão de cisalhamento"
      ],
      "metadata": {
        "id": "vBvf-dfhax6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def DSTLine(tau):\n",
        "        return (np.exp(-tau/tauStar)*((phi0-phiM)+phiM*np.exp(tau/tauStar))**2)/(phiM*(np.exp(tau/tauStar)-1-alpha*tau/tauStar)+phi0*(1+alpha*tau/tauStar))"
      ],
      "metadata": {
        "id": "hDHZAvdoa6qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Encontre a linha Shear Jamming em função dos valores de tensão definidos acima.\n",
        "* Esta função retorna frações de empacotamento em função da tensão de cisalhamento"
      ],
      "metadata": {
        "id": "EKW4-tRja-Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def shearJammingLine(tau):\n",
        "        return phiM+(phi0-phiM)*np.exp(-tau/tauStar)"
      ],
      "metadata": {
        "id": "essphW0LbHTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Estes são os valores x, ou as densidades que definem a linha DST e a linha SJ"
      ],
      "metadata": {
        "id": "qv6LHBQPbKEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    phiValuesDST = DSTLine(stressValues)\n",
        "    phiValuesSJ = shearJammingLine(stressValues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "hbYdR3MDbOHx",
        "outputId": "3bead428-ff0d-4725-c8b8-53abdc66360f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c14c78fcab98>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphiValuesDST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDSTLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstressValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mphiValuesSJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshearJammingLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstressValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DSTLine' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Isso gera a linha vertical que define o bloqueio sem atrito"
      ],
      "metadata": {
        "id": "TDas575ybSSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   phiValuesJamming = phi0*np.ones(100000)"
      ],
      "metadata": {
        "id": "ObAdbUcEbQo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Esta é outra linha vertical que não é vista no gráfico, mas atua como limite para a função fill_between"
      ],
      "metadata": {
        "id": "ELGadowubqX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    phiValuesBeyondJamming = phiValuesJamming+0.06"
      ],
      "metadata": {
        "id": "FW7pZYgib1Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Trace todas as quatro curvas, a curva DST, a curva SJ e as duas linhas verticais"
      ],
      "metadata": {
        "id": "EHq2iU3Rb6ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    pyplot.semilogy(phiValuesDST,stressValues,phiValuesSJ,stressValues,phiValuesJamming,stressValues,phiValuesBeyondJamming,stressValues,label = ['DST', 'SJ','J'],color=\"black\")"
      ],
      "metadata": {
        "id": "LhR-VnrLb-QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Isso sombreia a região entre DST e SJ verde (Esta é a região DST)"
      ],
      "metadata": {
        "id": "9qfhv0xicBLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   pyplot.fill_betweenx(stressValues,phiValuesDST,phiValuesSJ,where=phiValuesDST <= phiValuesSJ, facecolor='lightblue', interpolate=True)"
      ],
      "metadata": {
        "id": "jThA9OhFcGp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Isso sombreia a região entre SJ e interferência sem fricção azul (Esta é a região SJ)"
      ],
      "metadata": {
        "id": "KwC49V5scKG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    pyplot.fill_betweenx(stressValues,phiValuesSJ,phiValuesJamming,where=phiValuesSJ <= phiValuesJamming, facecolor='lightgreen', interpolate=True)"
      ],
      "metadata": {
        "id": "szReAem2cPHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Isso sombreia a região entre o bloqueio sem atrito e a linha vertical fora da vista cinza (esta é a região de bloqueio sem atrito)"
      ],
      "metadata": {
        "id": "IgQuqi3vcS0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    pyplot.fill_betweenx(stressValues,phiValuesJamming,phiValuesBeyondJamming,where=phiValuesJamming <= phiValuesBeyondJamming, facecolor='olive', interpolate=True)\n",
        "\n",
        "\n",
        "    pyplot.ylim(10**-1, 1000)\n",
        "    pyplot.xlim(phiM-.1,phi0+.05)\n",
        "\n",
        "    pyplot.xlabel(r\"Packing Fraction $\\phi$\")\n",
        "    pyplot.ylabel(r\"Shear Stress $ \\tau $ [Pa]\")\n",
        "    pyplot.title(\"Shear Jamming Phase Diagram\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def find_nearest(array, value):\n",
        "    array = np.asarray(array)\n",
        "    idx = (np.abs(array - value)).argmin()\n",
        "    return array[idx]\n",
        "\n",
        "\n",
        "\n",
        "def shearJammingPhaseDiagramTwoSystems(phi01,phiM1,tauStar1,alpha1,phi02,phiM2,tauStar2,alpha2,labels,DST=False,SJ=False):"
      ],
      "metadata": {
        "id": "xjYngw0jcjAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Isso gera um gráfico do diagrama de fase de interferência de cisalhamento usando o modelo Wyart-Cates. Este modelo é descrito no papel encontrado aqui:\n",
        "    * https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.112.098302\n",
        "    \n",
        "* Este modelo dá a taxa de cisalhamento em função da densidade de sua suspensão e em função da tensão de cisalhamento:\n",
        "* gammaDot = (1/eta_0)*tau*(1+phi/(phiM+(phi0-phiM)*e^(-tau/tauStar)))^alpha\n",
        "  * onde gammaDot é a taxa de cisalhamento, eta_0 é a viscosidade do solvente de suspensão tau é a tensão de cisalhamento, phi é a densidade, phi0 é a densidade de interferência sem atrito, phiM é a densidade de interferência por fricção e alpha é um parâmetro livre no modelo .\n",
        "    \n",
        "   * Estes são os valores y ou as tensões usadas para cada curva"
      ],
      "metadata": {
        "id": "WIa6G7Srcw85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   stressValues = np.linspace(10**-5,10**5,100000)"
      ],
      "metadata": {
        "id": "4ff-NX3mdN3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Encontre a linha DST em função dos valores de estresse definidos acima. Esta função retorna frações de empacotamento em função da tensão de cisalhamento"
      ],
      "metadata": {
        "id": "zC8-YGjZdRu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def DSTLine(tau,tauStar,phi0,phiM,alpha):\n",
        "        return (np.exp(-tau/tauStar)*((phi0-phiM)+phiM*np.exp(tau/tauStar))**2)/(phiM*(np.exp(tau/tauStar)-1-alpha*tau/tauStar)+phi0*(1+alpha*tau/tauStar))"
      ],
      "metadata": {
        "id": "ZDMiEMFldYHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Encontre a linha Shear Jamming em função dos valores de tensão definidos acima. Esta função retorna frações de empacotamento em função da tensão de cisalhamento"
      ],
      "metadata": {
        "id": "etPF98PXdbfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def shearJammingLine(tau,tauStar,phi0,phiM,alpha):\n",
        "        return phiM+(phi0-phiM)*np.exp(-tau/tauStar)"
      ],
      "metadata": {
        "id": "6m6FRYWddiJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Estes são os valores x, ou as densidades que definem a linha DST e a linha SJ para o sistema 1"
      ],
      "metadata": {
        "id": "2C_zZicjdlmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    phiValuesDST1 = DSTLine(stressValues,tauStar1,phi01,phiM1,alpha1)\n",
        "    phiValuesSJ1 = shearJammingLine(stressValues,tauStar1,phi01,phiM1,alpha1)"
      ],
      "metadata": {
        "id": "d2R2kuJrdrzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Estes são os valores x, ou as densidades que definem a linha DST e a linha SJ para o sistema 2."
      ],
      "metadata": {
        "id": "FqZBA2HIdugV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    phiValuesDST2 = DSTLine(stressValues,tauStar2,phi02,phiM2,alpha2)\n",
        "    phiValuesSJ2 = shearJammingLine(stressValues,tauStar2,phi02,phiM2,alpha2)"
      ],
      "metadata": {
        "id": "3E4JE-QDdzCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Isso gera a linha vertical que define o bloqueio sem atrito"
      ],
      "metadata": {
        "id": "8xB1Nj4cd2Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   phiValuesJamming1 = phi01*np.ones(100000)\n",
        "    phiValuesJamming2 = phi02*np.ones(100000)\n",
        "\n",
        "\n",
        "\n",
        "    if DST ==True:\n",
        "        pyplot.semilogy(phiValuesDST1,stressValues,label = 'DST-'+ labels[0],color=\"black\")"
      ],
      "metadata": {
        "id": "3mWsuU5gd7eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Plote todas as quatro curvas, a curva DST, a curva SJ e as duas linhas verticais para o primeiro sistema.\n"
      ],
      "metadata": {
        "id": "BNixWMcwd_Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        pyplot.semilogy(phiValuesDST2,stressValues,label = 'DST-'+ labels[1],color=\"red\")\n",
        "        pyplot.fill_betweenx(stressValues,phiValuesDST1,phiValuesSJ1,where=phiValuesDST1 <= phiValuesSJ1, facecolor='lightblue', interpolate=True)\n",
        "        pyplot.fill_betweenx(stressValues,phiValuesDST2,phiValuesSJ2,where=phiValuesDST2 <= phiValuesSJ2, facecolor='lightgreen', interpolate=True)\n",
        "        pyplot.semilogy(phiValuesSJ1,stressValues,label = 'SJ-'+ labels[0],color=\"black\")\n",
        "        pyplot.semilogy(phiValuesSJ2,stressValues,label = 'SJ-'+ labels[1],color=\"red\")\n",
        "    if SJ == True:\n",
        "        pyplot.semilogy(phiValuesSJ1,stressValues,label = 'SJ-'+ labels[0],color=\"black\")\n",
        "        pyplot.semilogy(phiValuesSJ2,stressValues,label = 'SJ-'+ labels[1],color=\"red\")\n",
        "        pyplot.semilogy(phiValuesJamming1,stressValues,label = 'J-'+ labels[0],color=\"black\")\n",
        "        pyplot.semilogy(phiValuesJamming2,stressValues,label = 'J-'+ labels[1],color=\"red\")\n",
        "        pyplot.fill_betweenx(stressValues,phiValuesSJ1,phiValuesJamming1,where=phiValuesSJ1 <= phiValuesJamming1, facecolor='lightgreen', interpolate=True)\n",
        "        pyplot.fill_betweenx(stressValues,phiValuesSJ2,phiValuesJamming2,where=phiValuesSJ2 <= phiValuesJamming2, facecolor='lightgreen', interpolate=True)\n",
        "\n",
        "\n",
        "\n",
        "    pyplot.legend()\n",
        "\n",
        "\n",
        "    phiM = min(phiM1,phiM2)\n",
        "    phi0 = max(phi01,phi02)\n",
        "\n",
        "    pyplot.ylim(10**-1, 1000)\n",
        "    pyplot.xlim(phiM-.05,phi0+.05)\n",
        "\n",
        "    pyplot.xlabel(r\"Packing Fraction $\\phi$\")\n",
        "    pyplot.ylabel(r\"Shear Stress $ \\tau $ [Pa]\")\n",
        "    5\n",
        "    if DST==True and SJ ==True:\n",
        "        pyplot.title(\"Shear Jamming Phase Diagram\")\n",
        "\n",
        "    if DST==True and SJ==False:\n",
        "        pyplot.title(\"Discontinuous Shear Thickening Regions\")\n",
        "\n",
        "    if DST==False and SJ==True:\n",
        "        pyplot.title(\"Shear Jamming Regions\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def WCModelComparison(topDir,outputDir,phi0,phiM,tauStar,alpha,beta=False):\n",
        "\n",
        "\n",
        "\n",
        "    listOfSubDirs = next(os.walk(topDir))[1]\n",
        "\n",
        "\n",
        "    stressValues = np.linspace(.0001,1e3,10000)\n",
        "\n",
        "    if beta==False:\n",
        "        def rescaledNewtonianViscosity(stress,phi):\n",
        "            return (1-phi/(phiM+(phi0-phiM)*np.exp(-stress/tauStar)))**(-alpha)\n",
        "    else:\n",
        "        def rescaledNewtonianViscosity(stress,phi):\n",
        "            return (1-phi/(phi0+(phiM-phi0)*np.exp((-tauStar/stress))**beta))**(-alpha)\n",
        "\n",
        "    for packingFraction in listOfSubDirs:\n",
        "        loadInAveragedData = np.load(os.path.join(topDir, packingFraction , r\"averagedDataVR.npy\" ))\n",
        "        loadInErrors = np.load(os.path.join(topDir, packingFraction , r\"errorsDataVR.npy\" ))\n",
        "\n",
        "        phiValues = (float(packingFraction)/100)*np.ones(10000)"
      ],
      "metadata": {
        "id": "-5AYVBG3eEJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Plotar a previsão de Wyart-Cates"
      ],
      "metadata": {
        "id": "wpnaaGi3eJmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "       pyplot.plot(stressValues,rescaledNewtonianViscosity(stressValues,phiValues))"
      ],
      "metadata": {
        "id": "FgRXEiNJeN6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Traçar dados reais"
      ],
      "metadata": {
        "id": "5bpsYszseQ_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        pyplot.errorbar(loadInAveragedData[:,4],loadInAveragedData[:,2],yerr=loadInErrors[:,2],label=packingFraction,marker='o',markersize=5)\n",
        "\n",
        "        pyplot.title(packingFraction)\n",
        "        pyplot.xlabel(\"Shear Stress [Pa]\")\n",
        "        pyplot.ylabel(\"Rescaled Viscosity\")\n",
        "        pyplot.yscale('log')\n",
        "        pyplot.xscale('log')\n",
        "        pyplot.ylim(1,1e3)\n",
        "        pyplot.xlim(1e-1,1e3)\n",
        "        pyplot.savefig(os.path.join(outputDir,str(float(packingFraction))+\".png\"))\n",
        "        pyplot.clf()\n",
        "\n",
        "\n",
        "def WCModelComparisonTwoSystems(topDir1,topDir2,outputDir,phi01,phiM1,tauStar1,alpha1,phi02,phiM2,tauStar2,alpha2,phi01E,phi02E,phiM1E,phiM2E,tauStar1E,tauStar2E,alpha1E,alpha2E,stretchedExponential=False,beta1=False,beta2=False):\n",
        "\n",
        "\n",
        "\n",
        "    dirsIn1 = next(os.walk(topDir1))[1]\n",
        "    dirsIn2 = next(os.walk(topDir2))[1]"
      ],
      "metadata": {
        "id": "Xp4BLUEdeVLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Eles precisam ser classificados, então temos que convertê-los de strings para floats e depois voltar"
      ],
      "metadata": {
        "id": "ots85WaNeZYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    dirsIn1 = np.sort([float(i) for i in dirsIn1])\n",
        "    dirsIn2 = np.sort([float(i) for i in dirsIn2])"
      ],
      "metadata": {
        "id": "U19_ZEMCed4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* De volta às strings!"
      ],
      "metadata": {
        "id": "UR9DV_Bqeglk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    dirsIn1 = [str(i) for i in dirsIn1]\n",
        "    dirsIn2 = [str(i) for i in dirsIn2]\n",
        "\n",
        "\n",
        "    stressValues = np.linspace(.0001,1e3,10000)\n",
        "\n",
        "    if stretchedExponential == False:\n",
        "        def rescaledNewtonianViscosity1(stress,phi):\n",
        "            return (1-phi/(phiM1+(phi01-phiM1)*np.exp(-stress/tauStar1)))**(-alpha1)\n",
        "\n",
        "        def rescaledNewtonianViscosity2(stress,phi):\n",
        "            return (1-phi/(phiM2+(phi02-phiM2)*np.exp(-stress/tauStar2)))**(-alpha2)\n",
        "    else:\n",
        "        def rescaledNewtonianViscosity1(stress,phi):\n",
        "            return (1-phi/(phi01+(phiM1-phi01)*np.exp((-stress/tauStar1)**beta1)))**(-alpha1)\n",
        "\n",
        "        def rescaledNewtonianViscosity2(stress,phi):\n",
        "            return (1-phi/(phi02+(phiM2-phi02)*np.exp((-stress/tauStar2)**beta2)))**(-alpha2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(0,len(dirsIn1)):\n",
        "\n",
        "        loadInAveragedData1 = np.load(os.path.join(topDir1,dirsIn1[i], r\"averagedDataVR.npy\"))\n",
        "        loadInErrors1 = np.load(os.path.join(topDir1,dirsIn1[i], r\"errorsDataVR.npy\"))\n",
        "\n",
        "        loadInAveragedData2 = np.load(os.path.join(topDir2,dirsIn2[i], r\"averagedDataVR.npy\"))\n",
        "        loadInErrors2 = np.load(os.path.join(topDir2,dirsIn2[i], r\"errorsDataVR.npy\"))\n",
        "\n",
        "        phiValues1 = (float(dirsIn1[i])/100)*np.ones(10000)\n",
        "        phiValues2 = (float(dirsIn2[i])/100)*np.ones(10000)"
      ],
      "metadata": {
        "id": "9pLm6nGKeniM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Plote a previsão de Wyart-Cates para 1"
      ],
      "metadata": {
        "id": "3qTwV1CAesQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        pyplot.plot(stressValues,rescaledNewtonianViscosity1(stressValues,phiValues1),label=\"Cornstarch Fit\")\n",
        "\n",
        "        if stretchedExponential ==False:\n",
        "            yMinE1 = (1-(float(dirsIn1[i])/100)/((phiM1-phiM1E)+((phi01-phi01E)-(phiM1-phiM1E))*np.exp(-stressValues/(tauStar1-tauStar1E))))**(-(alpha1-alpha1E))\n",
        "            yMaxE1 = (1-(float(dirsIn1[i])/100)/((phiM1+phiM1E)+((phi01+phi01E)-(phiM1+phiM1E))*np.exp(-stressValues/(tauStar1+tauStar1E))))**(-(alpha1+alpha1E))\n",
        "\n",
        "\n",
        "\n",
        "        yMinE1 = np.squeeze(yMinE1)\n",
        "\n",
        "\n",
        "        yMaxE1 = np.squeeze(yMaxE1)\n",
        "\n",
        "\n",
        "        pyplot.fill_between(stressValues,yMinE1,yMaxE1,yMinE1>=yMaxE1)"
      ],
      "metadata": {
        "id": "85u13BVkewTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Plotar a previsão de Wyart-Cates para 2"
      ],
      "metadata": {
        "id": "PCuxMcqZez54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        pyplot.plot(stressValues,rescaledNewtonianViscosity2(stressValues,phiValues2),label=\"GdCl Fit\")\n",
        "        if stretchedExponential==False:\n",
        "            yMinE2 = (1-(float(dirsIn2[i])/100)/((phiM2-phiM2E)+((phi02-phi02E)-(phiM2-phiM2E))*np.exp(-stressValues/(tauStar2-tauStar2E))))**(-(alpha2-alpha2E))\n",
        "            yMaxE2 = (1-(float(dirsIn2[i])/100)/((phiM2+phiM2E)+((phi02+phi02E)-(phiM2+phiM2E))*np.exp(-stressValues/(tauStar2+tauStar2E))))**(-(alpha2+alpha2E))\n",
        "\n",
        "\n",
        "\n",
        "        yMinE2 = np.squeeze(yMinE2)\n",
        "        yMaxE2 = np.squeeze(yMaxE2)\n",
        "        pyplot.fill_between(stressValues,yMinE2,yMaxE2,yMinE2>=yMaxE2)\n",
        "\n",
        "        pyplot.errorbar(loadInAveragedData1[:,4],loadInAveragedData1[:,2],yerr=loadInErrors1[:,2],label=dirsIn1[i]+\"C\",marker='o')\n",
        "        pyplot.errorbar(loadInAveragedData2[:,4],loadInAveragedData2[:,2],yerr=loadInErrors2[:,2],label=dirsIn2[i]+\"GdCl\",marker=\"D\")\n",
        "\n",
        "        figName = str(round(float(dirsIn1[i])))\n",
        "\n",
        "        pyplot.title(figName)\n",
        "        pyplot.xlabel(\"Shear Stress [Pa]\")\n",
        "        pyplot.ylabel(\"Rescaled Viscosity\")\n",
        "        pyplot.yscale('log')\n",
        "        pyplot.xscale('log')\n",
        "        pyplot.ylim(1,5e3)\n",
        "        pyplot.xlim(1e-1,1e3)\n",
        "        pyplot.legend()\n",
        "        pyplot.savefig(os.path.join(outputDir,str(float(figName))+\".png\"))\n",
        "        pyplot.clf()"
      ],
      "metadata": {
        "id": "2AvM0W5SsCWt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}